"""Stateless Execution Runner.

Implements the "Unrolled Codex" pattern for stateless agent execution
with context reconstruction from persistent event log.
"""

import asyncio
import logging
import os
import time
import uuid
from collections.abc import AsyncGenerator
from dataclasses import dataclass, field
from typing import Any

from google.adk.agents import LlmAgent
from google.adk.events import Event, EventActions
from google.adk.sessions import Session

from sre_agent.core.approval import (
    ApprovalManager,
    HumanApprovalRequest,
    get_approval_manager,
)
from sre_agent.core.context_compactor import (
    CompactionConfig,
    ContextCompactor,
    WorkingContext,
    get_context_compactor,
)
from sre_agent.core.policy_engine import (
    PolicyDecision,
    PolicyEngine,
    get_policy_engine,
)
from sre_agent.core.prompt_composer import (
    DomainContext,
    PromptComposer,
    SessionSummary,
    get_prompt_composer,
)

logger = logging.getLogger(__name__)


@dataclass
class RunnerConfig:
    """Configuration for the Runner."""

    # Enable policy enforcement
    enforce_policy: bool = field(
        default_factory=lambda: os.getenv("SRE_AGENT_ENFORCE_POLICY", "true").lower()
        == "true"
    )

    # Enable context compaction
    enable_compaction: bool = True

    # Enable three-tier prompts
    use_three_tier_prompts: bool = True

    # Maximum turns per execution
    max_turns: int = 50

    # Timeout for execution in seconds
    execution_timeout: float = 300.0

    # Compaction configuration
    compaction_config: CompactionConfig = field(default_factory=CompactionConfig)


@dataclass
class ExecutionContext:
    """Context for a single execution turn."""

    session_id: str
    user_id: str
    project_id: str | None
    turn_number: int
    start_time: float
    domain_context: DomainContext | None = None


@dataclass
class ExecutionResult:
    """Result of an execution turn."""

    success: bool
    events: list[Event]
    approval_required: bool = False
    approval_request: HumanApprovalRequest | None = None
    error: str | None = None
    turn_number: int = 0
    duration_ms: float = 0.0


class Runner:
    """Stateless execution harness for the SRE Agent.

    Implements the Unrolled Codex pattern:
    1. Each turn reconstructs context from the event log
    2. Policy engine intercepts all tool calls
    3. Context compaction manages token budget
    4. Human approval gates write operations
    """

    def __init__(
        self,
        agent: LlmAgent,
        config: RunnerConfig | None = None,
        policy_engine: PolicyEngine | None = None,
        context_compactor: ContextCompactor | None = None,
        prompt_composer: PromptComposer | None = None,
        approval_manager: ApprovalManager | None = None,
    ) -> None:
        """Initialize the runner.

        Args:
            agent: The LLM agent to run
            config: Runner configuration
            policy_engine: Policy engine for tool validation
            context_compactor: Context compactor for history management
            prompt_composer: Prompt composer for message construction
            approval_manager: Approval manager for write operations
        """
        self.agent = agent
        self.config = config or RunnerConfig()
        self.policy_engine = policy_engine or get_policy_engine()
        self.context_compactor = context_compactor or get_context_compactor(
            self.config.compaction_config
        )
        self.prompt_composer = prompt_composer or get_prompt_composer()
        self.approval_manager = approval_manager or get_approval_manager()

        # Track execution state
        self._active_executions: dict[str, ExecutionContext] = {}

    async def run_turn(
        self,
        session: Session,
        user_message: str,
        user_id: str,
        project_id: str | None = None,
        domain_context: DomainContext | None = None,
    ) -> AsyncGenerator[Event, None]:
        """Execute a single turn of the agent.

        This is the main entry point for stateless execution. Each call:
        1. Reconstructs context from session history
        2. Composes the prompt using three tiers
        3. Runs the agent with policy enforcement
        4. Yields events as they are generated

        Args:
            session: ADK session with event history
            user_message: Current user message
            user_id: User identifier
            project_id: GCP project context
            domain_context: Additional domain context

        Yields:
            Events generated by the agent
        """
        start_time = time.time()
        session_id = session.id
        logger.debug(f"Runner.run_turn START for session {session_id}")

        # Create execution context
        turn_number = len(session.events) if session.events else 0
        exec_ctx = ExecutionContext(
            session_id=session_id,
            user_id=user_id,
            project_id=project_id,
            turn_number=turn_number,
            start_time=start_time,
            domain_context=domain_context,
        )
        self._active_executions[session_id] = exec_ctx

        try:
            # Refresh agent tools from current configuration for dynamic filtering
            try:
                from sre_agent.agent import get_enabled_base_tools

                enabled_tools = get_enabled_base_tools()
                if hasattr(self.agent, "tools"):
                    self.agent.tools = enabled_tools
                    logger.debug(
                        f"Refreshed {len(enabled_tools)} tools for agent {self.agent.name}"
                    )
            except (ImportError, AttributeError, Exception) as e:
                logger.debug(f"Could not refresh agent tools dynamically: {e}")

            # Step 1: Get working context (with compaction if needed)
            working_context = await self._get_working_context(session)

            # Step 2: Compose the prompt
            if self.config.use_three_tier_prompts:
                enhanced_message = self._compose_message(
                    user_message, working_context, domain_context
                )
            else:
                enhanced_message = user_message

            # Step 3: Check for pending approvals
            pending = self.approval_manager.get_pending_requests(session_id)
            if pending:
                yield self._create_approval_pending_event(pending)
                return

            # Step 4: Run the agent with policy enforcement
            async for event in self._run_with_policy(
                session, enhanced_message, exec_ctx
            ):
                yield event

        except asyncio.TimeoutError:
            logger.error(f"Execution timeout for session {session_id}")
            yield self._create_error_event("Execution timed out")

        except Exception as e:
            logger.error(f"Execution error: {e}", exc_info=True)
            yield self._create_error_event(str(e))

        finally:
            if session_id in self._active_executions:
                del self._active_executions[session_id]

            duration = (time.time() - start_time) * 1000
            logger.info(f"Turn completed in {duration:.0f}ms")

    async def _get_working_context(self, session: Session) -> WorkingContext:
        """Get working context from session with compaction.

        Args:
            session: Session with event history

        Returns:
            Working context for the LLM
        """
        if not self.config.enable_compaction:
            # Return all events as recent
            events = self._extract_events(session)
            return WorkingContext(
                summary=SessionSummary(summary_text="Full history mode."),
                recent_events=events,
            )

        events = self._extract_events(session)
        return self.context_compactor.get_working_context(
            session_id=session.id,
            events=events,
        )

    def _extract_events(self, session: Session) -> list[dict[str, Any]]:
        """Extract events from session as dictionaries.

        Args:
            session: ADK session

        Returns:
            List of event dictionaries
        """
        events = []
        for event in session.events or []:
            event_dict: dict[str, Any] = {
                "type": "unknown",
                "timestamp": getattr(event, "timestamp", ""),
                "content": "",
            }

            # Determine event type
            if event.author == "user":
                event_dict["type"] = "user_message"
            elif hasattr(event, "content") and event.content:
                parts = getattr(event.content, "parts", None)
                if parts:
                    for part in parts:
                        if hasattr(part, "function_call") and part.function_call:
                            event_dict["type"] = "tool_call"
                            event_dict["tool_name"] = part.function_call.name
                        elif (
                            hasattr(part, "function_response")
                            and part.function_response
                        ):
                            event_dict["type"] = "tool_output"
                            event_dict["tool_name"] = part.function_response.name
                        elif hasattr(part, "text"):
                            event_dict["type"] = "model_thought"

            # Extract content
            if hasattr(event, "content") and event.content:
                parts = getattr(event.content, "parts", None)
                if parts:
                    parts_text: list[str] = []
                    for part in parts:
                        if hasattr(part, "text") and part.text:
                            parts_text.append(str(part.text))
                        elif (
                            hasattr(part, "function_response")
                            and part.function_response
                        ):
                            resp = getattr(part.function_response, "response", None)
                            if resp is not None:
                                parts_text.append(str(resp))
                    event_dict["content"] = "\n".join(parts_text)

            events.append(event_dict)

        return events

    def _compose_message(
        self,
        user_message: str,
        working_context: WorkingContext,
        domain_context: DomainContext | None = None,
    ) -> str:
        """Compose the enhanced user message.

        Args:
            user_message: Original user message
            working_context: Working context from compactor
            domain_context: Domain context for Developer role

        Returns:
            Enhanced message string
        """
        # Build session summary for prompt
        session_summary = working_context.summary

        # Format recent events
        recent_formatted = []
        for event in working_context.recent_events[-5:]:
            event_type = event.get("type", "unknown")
            content = event.get("content", "")[:200]
            recent_formatted.append(f"[{event_type}]: {content}")

        # Compose the message with context
        parts = []

        # Add domain context if available
        if domain_context:
            if domain_context.project_id:
                parts.append(f"[CURRENT PROJECT: {domain_context.project_id}]")
            if domain_context.investigation_phase:
                parts.append(f"[PHASE: {domain_context.investigation_phase}]")

        # Add session summary
        if session_summary.summary_text:
            parts.append(f"[SESSION CONTEXT]\n{session_summary.summary_text}")

        # Add recent events
        if recent_formatted:
            parts.append("[RECENT EVENTS]\n" + "\n".join(recent_formatted))

        # Add user message
        parts.append(f"[USER REQUEST]\n{user_message}")

        return "\n\n".join(parts)

    async def _run_with_policy(
        self,
        session: Session,
        message: str,
        exec_ctx: ExecutionContext,
    ) -> AsyncGenerator[Event, None]:
        """Run agent with policy enforcement.

        Args:
            session: ADK session
            message: Enhanced user message
            exec_ctx: Execution context

        Yields:
            Events from agent execution
        """
        from google.adk.agents import InvocationContext, RunConfig
        from google.adk.sessions import InMemorySessionService
        from google.genai import types

        # Create invocation context
        user_content = types.Content(
            role="user",
            parts=[types.Part.from_text(text=message)],
        )

        # Create a minimal session service for invocation context
        session_service = InMemorySessionService()  # type: ignore[no-untyped-call]

        # Wire in the ADK memory service so PreloadMemoryTool and
        # LoadMemoryTool can function via tool_context.search_memory()
        from sre_agent.memory.factory import get_adk_memory_service

        inv_ctx = InvocationContext(
            invocation_id=str(uuid.uuid4()),
            agent=self.agent,
            session=session,
            session_service=session_service,
            user_content=user_content,
            run_config=RunConfig(),
            memory_service=get_adk_memory_service(),
        )

        # Run agent and intercept tool calls
        try:
            async for event in self.agent.run_async(inv_ctx):
                # Check for function calls that need policy evaluation
                if self.config.enforce_policy:
                    # _intercept_tool_calls is an async generator - we must iterate over it
                    intercepted = False
                    async for result_event in self._intercept_tool_calls(
                        event, exec_ctx
                    ):
                        yield result_event
                        intercepted = True

                    if intercepted:
                        continue

                yield event

        except Exception as e:
            logger.error(f"Agent execution error: {e}", exc_info=True)
            yield self._create_error_event(f"Agent error: {e}")

    async def _intercept_tool_calls(
        self, event: Event, exec_ctx: ExecutionContext
    ) -> AsyncGenerator[Event, None]:
        """Intercept and validate tool calls.

        Args:
            event: Event to check
            exec_ctx: Execution context

        Yields:
            Modified event if intervention needed, None otherwise
        """
        from google.genai import types

        if not hasattr(event, "content") or not event.content:
            return

        parts = getattr(event.content, "parts", None)
        if not parts:
            return

        for part in parts:
            if hasattr(part, "function_call") and part.function_call:
                func_call = part.function_call
                tool_name: str = str(func_call.name) if func_call.name else "unknown"
                tool_args = dict(func_call.args) if func_call.args else {}

                # Evaluate policy
                decision = self.policy_engine.evaluate(
                    tool_name=tool_name,
                    tool_args=tool_args,
                    user_id=exec_ctx.user_id,
                    project_id=exec_ctx.project_id,
                )

                if not decision.allowed:
                    # CRITICAL: We MUST yield the original call event first,
                    # so the client/ADK loop sees the call before the response.
                    yield event

                    # Yield the rejection message
                    rejection_event = self._create_policy_rejection_event(decision)
                    yield rejection_event

                    # Yield a dummy function response to satisfy the ADK event list
                    # This prevents: ValueError: No function call event found for function responses ids
                    yield Event(
                        invocation_id=event.invocation_id,
                        author="system",
                        content=types.Content(
                            role="user",
                            parts=[
                                types.Part(
                                    function_response=types.FunctionResponse(
                                        name=tool_name,
                                        id=func_call.id,
                                        response={
                                            "status": "error",
                                            "error": decision.reason,
                                        },
                                    )
                                )
                            ],
                        ),
                    )
                    return

                if decision.requires_approval:
                    # Yield the call event before the approval request
                    yield event
                    yield await self._create_approval_request_event(
                        decision, tool_args, exec_ctx
                    )
                    return

        yield event  # Yield the original event if no interception occurred

    def _create_policy_rejection_event(self, decision: PolicyDecision) -> Event:
        """Create event for policy rejection."""
        from google.genai import types

        rejection_text = f"""⛔ **Policy Rejection**

Tool: `{decision.tool_name}`
Reason: {decision.reason}

This operation is not allowed. Please use a read-only alternative or request elevated permissions.
"""

        return Event(
            invocation_id=str(uuid.uuid4()),
            author="system",
            content=types.Content(
                role="model",
                parts=[types.Part.from_text(text=rejection_text)],
            ),
        )

    async def _create_approval_request_event(
        self,
        decision: PolicyDecision,
        tool_args: dict[str, Any],
        exec_ctx: ExecutionContext,
    ) -> Event:
        """Create event for approval request."""
        from google.genai import types

        request = self.approval_manager.create_request(
            session_id=exec_ctx.session_id,
            user_id=exec_ctx.user_id,
            tool_name=decision.tool_name,
            tool_args=tool_args,
            reason=f"Agent requested to execute {decision.tool_name}",
            risk_assessment=decision.risk_assessment or "No assessment available",
        )

        approval_text = f"""⏸️ **Human Approval Required**

Tool: `{decision.tool_name}`
Risk Level: {decision.access_level.value}

{decision.risk_assessment or ""}

**Request ID**: `{request.request_id}`

Please approve or reject this operation to continue.
"""

        return Event(
            invocation_id=str(uuid.uuid4()),
            author="system",
            content=types.Content(
                role="model",
                parts=[types.Part.from_text(text=approval_text)],
            ),
            actions=EventActions(
                state_delta={
                    "pending_approval": request.request_id,
                    "approval_tool": decision.tool_name,
                }
            ),
        )

    def _create_approval_pending_event(
        self, pending: list[HumanApprovalRequest]
    ) -> Event:
        """Create event for pending approvals."""
        from google.genai import types

        pending_text = "⏸️ **Pending Approvals**\n\n"
        pending_text += "The following operations are awaiting approval:\n\n"

        for req in pending:
            pending_text += f"- `{req.tool_name}` (ID: {req.request_id})\n"

        pending_text += "\nPlease approve or reject to continue."

        return Event(
            invocation_id=str(uuid.uuid4()),
            author="system",
            content=types.Content(
                role="model",
                parts=[types.Part.from_text(text=pending_text)],
            ),
        )

    def _create_error_event(self, error_message: str) -> Event:
        """Create an error event."""
        from google.genai import types

        return Event(
            invocation_id=str(uuid.uuid4()),
            author="system",
            content=types.Content(
                role="model",
                parts=[types.Part.from_text(text=f"❌ Error: {error_message}")],
            ),
        )

    async def process_approval(
        self,
        session_id: str,
        request_id: str,
        approved: bool,
        approver_id: str,
        comment: str | None = None,
    ) -> bool:
        """Process an approval decision.

        Args:
            session_id: Session ID
            request_id: Approval request ID
            approved: Whether approved
            approver_id: ID of approver
            comment: Optional comment

        Returns:
            True if processed successfully
        """
        try:
            self.approval_manager.process_decision(
                session_id=session_id,
                request_id=request_id,
                approved=approved,
                approver_id=approver_id,
                comment=comment,
            )
            return True
        except ValueError as e:
            logger.error(f"Failed to process approval: {e}")
            return False

    def get_pending_approvals(self, session_id: str) -> list[HumanApprovalRequest]:
        """Get pending approval requests for a session."""
        return self.approval_manager.get_pending_requests(session_id)


# Factory function for creating runners
def create_runner(
    agent: LlmAgent,
    enforce_policy: bool = True,
    enable_compaction: bool = True,
    use_three_tier_prompts: bool = True,
) -> Runner:
    """Create a configured Runner instance.

    Args:
        agent: LLM agent to run
        enforce_policy: Enable policy enforcement
        enable_compaction: Enable context compaction
        use_three_tier_prompts: Enable three-tier prompt composition

    Returns:
        Configured Runner instance
    """
    config = RunnerConfig(
        enforce_policy=enforce_policy,
        enable_compaction=enable_compaction,
        use_three_tier_prompts=use_three_tier_prompts,
    )
    return Runner(agent=agent, config=config)
