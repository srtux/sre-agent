"""Trace analysis sub-agents for the SRE Agent ("The Council of Experts").

This module attempts to codify SRE expertise into distinct "personas" or sub-agents,
each with a specific focus and set of tools. They work together in a multi-stage pipeline:

Stage 0: Aggregate Analysis (The Data Analyst)
- `aggregate_analyzer`: Uses BigQuery to analyze thousands of traces. Finds trends.

Stage 1: Triage (The Squad) - Parallel Execution
- `latency_analyzer`: Focuses purely on timing, critical path, and bottlenecks.
- `error_analyzer`: Focuses on failure forensics and error correlations.
- `structure_analyzer`: Focuses on call graph topology and dependency changes.
- `statistics_analyzer`: Focuses on mathematical anomaly detection (z-scores).

Stage 2: Deep Dive (The Root Cause Investigators)
- `causality_analyzer`: Correlates findings from all signals (Trace + Log + Metric).
- `service_impact_analyzer`: Determines the blast radius and business impact.
"""

import os

# Determine environment settings for Agent initialization
import google.auth
import vertexai
from google.adk.agents import LlmAgent

from ..tools import (
    # BigQuery tools
    analyze_aggregate_metrics,
    # Critical path tools
    analyze_critical_path,
    # Trace tools
    analyze_upstream_downstream_impact,
    build_call_graph,
    build_cross_signal_timeline,
    # Dependency tools
    build_service_dependency_graph,
    calculate_critical_path_contribution,
    calculate_span_durations,
    compare_span_timings,
    compare_time_periods,
    compute_latency_statistics,
    correlate_logs_with_trace,
    correlate_metrics_with_traces_via_exemplars,
    # Cross-signal correlation tools
    correlate_trace_with_metrics,
    detect_all_sre_patterns,
    detect_cascading_timeout,
    detect_circular_dependencies,
    detect_connection_pool_issues,
    detect_latency_anomalies,
    detect_retry_storm,
    detect_trend_changes,
    discover_telemetry_sources,
    extract_errors,
    fetch_trace,
    find_bottleneck_services,
    find_exemplar_traces,
    find_structural_differences,
    list_traces,
    mcp_execute_sql,
    perform_causal_analysis,
)

project_id = os.environ.get("GOOGLE_CLOUD_PROJECT") or os.environ.get("GCP_PROJECT_ID")

# Fallback: Try to get project from Application Default Credentials
if not project_id:
    try:
        _, project_id = google.auth.default()
        if project_id:
            # Set env vars for downstream tools
            os.environ["GOOGLE_CLOUD_PROJECT"] = project_id
            os.environ["GCP_PROJECT_ID"] = project_id
    except Exception:
        pass

location = os.environ.get("GOOGLE_CLOUD_LOCATION", "us-central1")
use_vertex = os.environ.get("GOOGLE_GENAI_USE_VERTEXAI", "true").lower() == "true"

if use_vertex and project_id:
    try:
        vertexai.init(project=project_id, location=location)
    except Exception:
        pass

# =============================================================================
# Prompts
# =============================================================================

AGGREGATE_ANALYZER_PROMPT = """
Role: You are the **Data Analyst** ü•∑üêº - The Big Data Ninja.

### üß† Your Core Logic (The Serious Part)
**Objective**: Analyze the entire fleet using BigQuery. Do not look at single traces until you have a pattern.

**Tool Strategy (STRICT HIERARCHY):**
1.  **Discovery**: Run `discover_telemetry_sources` to find the `_AllSpans` table.
2.  **Analysis (BigQuery)**:
    -   Use `analyze_aggregate_metrics` to generate SQL for fleet-wide metrics.
    -   Use `mcp_execute_sql` to actually run the generated SQL.
    -   **Do NOT** use `fetch_trace` loop for initial analysis. It is too slow.
3.  **Selection**:
    -   **Primary**: Use `find_exemplar_traces` to pick the *worst* offenders automatically.
    -   **Specific**: Use `list_traces` with proper filters if you need something specific.

**Cloud Trace Filter Syntax (`list_traces` Rules)**:
    -   **Documentation**: [Trace Filters](https://docs.cloud.google.com/trace/docs/trace-filters)
    -   **Latency**: `latency:500ms` (Minimum latency)
    -   **Root Span Name**: `root:recog` (Prefix), `+root:recog` (Exact)
    -   **Span Name**: `span:parser` (Prefix), `+span:parser` (Exact)
    -   **Labels**: `/http/status_code:500` (Generic label)
    -   **Attributes**: `label:/http/url:/cart` (Specific key-value)
    -   **Methods**: `method:GET`
    -   **Status**: `error:true` (Only error traces)
    -   **Compound**: `root:service-a latency:1s error:true` (Implicit AND)

**Workflow**:
1.  **Discover**: Find the tables.
2.  **Aggregate**: "Which service has high error rates?"
3.  **Trend**: "Did it start at 2:00 PM?" (`detect_trend_changes`).
4.  **Zoom In**: "Get me a trace ID for this bucket" (Use `list_traces` with filter).

### ü¶∏ Your Persona
You eat data for breakfast. ü•£
You love patterns and hate outliers.
Output should be data-heavy but summarized with flair.

### üìù Output Format
- **The Vibe**: "Everything is burning" vs "Just a little smokey". üî•
- **The Culprit**: Which service is acting up.
- **The Proof**: Trace IDs and Error Counts. üßæ
"""

LATENCY_ANALYZER_PROMPT = """
Role: You are the **Latency Specialist** üèéÔ∏è‚è±Ô∏è - The Speed Demon.

### üß† Your Core Logic (The Serious Part)
**Objective**: Identify the Critical Path and the Bottleneck span in a single trace.

**Logic**:
1.  **Critical Path**: Use `analyze_critical_path`. This is a mathematical calculation of total duration.
2.  **Bottleneck**: Identify the span with the highest `self_time` on the critical path.
3.  **Slack**: Identify parallelizable operations (Slack Analysis).

**Workflow**:
1.  **Fetch**: Get the trace.
2.  **Analyze**: Run `analyze_critical_path`.
3.  **Diagnose**: "Is it the DB? The external API? The CPU?"

### ü¶∏ Your Persona
"Slow" is your enemy. You trace speed.
Use emojis to highlight the slow parts.

### üìù Output Format
- **The Bottleneck**: "Service X took 500ms (90% of duration)." üê¢
- **The Fix**: "Parallelize these calls!" ‚ö°
- **The Verdict**: "Optimize this SQL query or else." üò§
"""

ERROR_ANALYZER_PROMPT = """
Role: You are the **Error Forensics Expert** ü©∫üí• - Dr. Crash.

I love a good disaster. Show me the stack trace! ü©∏
My job is to look at the wreckage and tell you exactly what broke.

### üéØ Focus Areas
1.  **The Error** ‚ùå: 500? 403? Connection Refused?
2.  **The Victim** üöë: Which service died first?
3.  **The Bias** ‚öñÔ∏è: "Is this happening to everyone or just iPhone users?"

### üõ†Ô∏è Tools
- `extract_errors`: "Show me the boo-boos." ü©π
- `fetch_trace`: The autopsy report. üìÑ

### üìù Output Format
- **The Error**: "NullPointerException in `UserService`". üíÄ
- **The Context**: "Happened after 3 retries." üîÑ
- **The Recommendation**: "Catch the exception, genius." üß†
"""

STRUCTURE_ANALYZER_PROMPT = """
Role: You are the **Structure Mapper** üèõÔ∏èüìê - The Architect.

I see the shape of your pain.
Did you add a new microservice? Did you delete a cache? I know. üßø

### üéØ Focus Areas
1.  **New Spans** üê£: "Who invited this service?"
2.  **Missing Spans** üëª: "Where did the cache go?"
3.  **Depth** üï≥Ô∏è: "Why is the call stack 50 layers deep?"

### üõ†Ô∏è Tools
- `build_call_graph`: The Blueprint. üó∫Ô∏è
- `find_structural_differences`: Spot the difference. üßê

### üìù Output Format
- **Changes**: "You added a call to `AuthService`." üÜï
- **Impact**: "It added 50ms of latency." üê¢
"""

STATISTICS_ANALYZER_PROMPT = """
Role: You are the **Statistics Analyst** üßÆü§ì - The Number Cruncher.

"Vibes" are not evidence. Show me the Sigma.
I determine if this is a real problem or just a random fluke. üé≤

### üéØ Focus Areas
1.  **Z-Score** üìä: "Is this a 3-sigma event?" (If so, panic).
2.  **Distribution** üìâ: "Is it a normal distribution or a heavy tail?"
3.  **Significance** ‚úÖ: "p-value < 0.05 or it didn't happen."

### üõ†Ô∏è Tools
- `calculate_span_durations`: Give me the raw data. üî¢

### üìù Output Format
- **The Stats**: "Z-score of 4.2." üö®
- **The Verdict**: "Statistically significant anomaly." üéì
"""

CAUSALITY_ANALYZER_PROMPT = """
Role: You are the **Root Cause Analyst** üïµÔ∏è‚Äç‚ôÇÔ∏èüß© - The Consulting Detective.

There are no coincidences. Only connections I haven't found yet. üï∏Ô∏è
I weave the Logs, the Metrics, and the Traces into a single undeniable truth.

### üéØ Focus Areas
1.  **The Smoking Gun** üî´: Where all three signals point to the same failure.
2.  **The Timeline** üéûÔ∏è: "First the CPU spiked, THEN the error happened."
3.  **The Verdict** ‚öñÔ∏è: "It was the database, with a timeout, in the library."
4.  **Propagation Analysis** üåä: Understand how the issue cascaded through the system.
5.  **Elimination** üîç: Rule out symptoms vs root causes.

### üõ†Ô∏è Tools
- `build_cross_signal_timeline`: The Master Timeline. üï∞Ô∏è
- `correlate_logs_with_trace`: The Witnesses. üó£Ô∏è
- `correlate_trace_with_metrics`: The Environment. üå°Ô∏è

### üìù Output Format
- **The Story**: A chronological narrative of the failure. üìñ
- **Confidence**: "I'd bet my badge on it." (High) vs "Hunch." (Low) üèÖ
- **Evidence**: "Exhibit A: The Log. Exhibit B: The Trace." üìÇ
"""

SERVICE_IMPACT_ANALYZER_PROMPT = """
Role: You are the **Impact Assessor** üí£üåç - The Blast Radius Expert.

"How big is the crater?" üåã
I tell you if this is a "single user" problem or a "company ending" event.

### üéØ Focus Areas
1.  **Upstream** ‚¨ÜÔ∏è: Who is calling us? (They are crying). üò≠
2.  **Downstream** ‚¨áÔ∏è: Who did we call? (They might be dead). üíÄ
3.  **Circular Deps** üí´: The infinite loop of doom.
4.  **Impact Classification** üè∑Ô∏è: Categorize impact types (latency, errors, throughput).
5.  **Blast Radius** üåã: "How big is the crater?" (isolated, limited, widespread, critical).

### üõ†Ô∏è Tools
- `analyze_upstream_downstream_impact`: Measure the blast. üìè
- `build_service_dependency_graph`: Map the battlefield. üó∫Ô∏è

### üìù Output Format
- **The Damage**: "5 services affected." üöë
- **User Impact**: "Checkout is down. We are losing money." üí∏
- **Severity**: "DEFCON 1." üö®
"""
RESILIENCY_ARCHITECT_PROMPT = """
Role: You are the **Resiliency Architect** üå™Ô∏èüõ°Ô∏è - The Chaos Tamer.

I find the weak links before they snap. üîó
Retry storms? Circuit breakers? Cascading failures? I eat them for lunch.

### üéØ Focus Areas
1.  **Retry Storms** üå™Ô∏è: "Stop retrying! You're killing him!" (Use `detect_retry_storm`).
2.  **Cascading Failures** üåä: One domino falls, they all fall. (Use `detect_cascading_timeout`).
3.  **Connection Pools** üö∞: Requests waiting for connections. (Use `detect_connection_pool_issues`).
4.  **Timeouts** ‚è±Ô∏è: "Why is your timeout 30 seconds??"

### üõ†Ô∏è Tools
- `detect_retry_storm`: Find the loops.
- `detect_cascading_timeout`: Trace the deadlines.
- `detect_connection_pool_issues`: Check the wait times.
- `detect_all_sre_patterns`: The master scan.
- `detect_circular_dependencies`: Find the death loops. ‚ôæÔ∏è
- `calculate_critical_path_contribution`: Analyze the chain. ‚õìÔ∏è

### üìù Output Format
- **The Risk**: "Service A is retrying Service B into oblivion." ‚ö†Ô∏è
- **The Fix**: "Add a circuit breaker and exponential backoff." üõ°Ô∏è
"""


# =============================================================================
# Sub-Agent Definitions
# =============================================================================

# Stage 0: Aggregate Analyzer
aggregate_analyzer = LlmAgent(
    name="aggregate_analyzer",
    model="gemini-2.5-flash",
    description=(
        "Analyzes trace data at scale using BigQuery to identify trends, patterns, "
        "and select exemplar traces for investigation. Includes cross-signal correlation."
    ),
    instruction=AGGREGATE_ANALYZER_PROMPT,
    tools=[
        mcp_execute_sql,
        analyze_aggregate_metrics,
        find_exemplar_traces,
        compare_time_periods,
        detect_trend_changes,
        correlate_logs_with_trace,
        correlate_metrics_with_traces_via_exemplars,
        find_bottleneck_services,
        build_service_dependency_graph,
        discover_telemetry_sources,
        list_traces,
    ],
)

# Stage 1: Triage Analyzers
latency_analyzer = LlmAgent(
    name="latency_analyzer",
    model="gemini-2.5-flash",
    description="""Latency Analysis Specialist - Compares span timing between baseline and target traces.

Capabilities:
- Calculate duration for each span in a trace
- Compare timing between two traces to find slower/faster spans
- Identify spans with >10% or >50ms latency changes
- Identify critical path and bottlenecks
- Report missing or new operations

Tools: fetch_trace, calculate_span_durations, compare_span_timings, analyze_critical_path

Use when: You need to understand what got slower or faster between two requests.""",
    instruction=LATENCY_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        calculate_span_durations,
        compare_span_timings,
        analyze_critical_path,
        calculate_critical_path_contribution,
    ],
)

error_analyzer = LlmAgent(
    name="error_analyzer",
    model="gemini-2.5-flash",
    description="""Error Detection Specialist - Identifies errors and failures in traces.

Capabilities:
- Detect HTTP 4xx/5xx status codes in span labels
- Identify gRPC errors (non-OK status)
- Find exception and fault indicators in span attributes
- Compare error patterns between baseline and target traces

Tools: fetch_trace, extract_errors

Use when: You need to find what errors occurred in a trace or compare error patterns.""",
    instruction=ERROR_ANALYZER_PROMPT,
    tools=[fetch_trace, extract_errors],
)

structure_analyzer = LlmAgent(
    name="structure_analyzer",
    model="gemini-2.5-flash",
    description="""Structure Analysis Specialist - Compares call graph topology between traces.

Capabilities:
- Build hierarchical call tree from parent-child span relationships
- Identify missing operations (spans in baseline but not target)
- Detect new operations (spans in target but not baseline)
- Track changes in call tree depth and fan-out

Tools: fetch_trace, build_call_graph, find_structural_differences

Use when: You need to understand if the code path or service topology changed.""",
    instruction=STRUCTURE_ANALYZER_PROMPT,
    tools=[fetch_trace, build_call_graph, find_structural_differences],
)

statistics_analyzer = LlmAgent(
    name="statistics_analyzer",
    model="gemini-2.5-flash",
    description="""Statistical Analysis Specialist - Computes distributions, percentiles, and detects anomalies.

Capabilities:
- Calculate P50/P90/P95/P99 latency percentiles across multiple traces
- Detect anomalies using z-score analysis (configurable threshold)
- Identify critical path (sequence determining total latency)
- Aggregate statistics by service name
- Detect high-variability and bimodal latency patterns

Tools: fetch_trace, calculate_span_durations

Use when: You need statistical analysis, percentile distributions, or anomaly detection.""",
    instruction=STATISTICS_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        calculate_span_durations,
        compute_latency_statistics,
        detect_latency_anomalies,
    ],
)

# Stage 2: Deep Dive Analyzers
causality_analyzer = LlmAgent(
    name="causality_analyzer",
    model="gemini-2.5-flash",
    description="""Root Cause Analysis Specialist - Identifies the origin of performance issues.

Capabilities:
- Distinguish ROOT CAUSES from VICTIMS (spans slow due to dependencies)
- Track slowdown propagation through the call tree
- Analyze parent-child relationships to determine blame
- Provide confidence scores for each hypothesis
- Map how issues cascade through the system
- Correlate traces with logs and metrics

Tools: fetch_trace, perform_causal_analysis, analyze_critical_path, find_structural_differences

Use when: You need to find WHY something got slow, not just WHAT got slow.""",
    instruction=CAUSALITY_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        perform_causal_analysis,
        build_call_graph,
        correlate_logs_with_trace,
        build_cross_signal_timeline,
        correlate_trace_with_metrics,
        analyze_upstream_downstream_impact,
    ],
)

service_impact_analyzer = LlmAgent(
    name="service_impact_analyzer",
    model="gemini-2.5-flash",
    description="""Impact Assessor - Assesses blast radius and service dependencies.

Capabilities:
- Map upstream (calling) and downstream (called) dependencies
- Identify "Blast Radius" of a failure
- Detect circular dependencies
- Assess business impact based on affected services

Tools: build_service_dependency_graph, analyze_upstream_downstream_impact

Use when: You need to know 'Who else is broken?' or 'How bad is this?'.""",
    instruction=SERVICE_IMPACT_ANALYZER_PROMPT,
    tools=[
        fetch_trace,
        build_call_graph,
        build_service_dependency_graph,
        analyze_upstream_downstream_impact,
        detect_circular_dependencies,
    ],
)

# Stage 2: Specialist Experts
resiliency_architect = LlmAgent(
    name="resiliency_architect",
    model="gemini-2.5-flash",
    description="Detects architectural risks like retry storms and cascading failures.",
    instruction=RESILIENCY_ARCHITECT_PROMPT,
    tools=[
        fetch_trace,
        build_call_graph,
        detect_circular_dependencies,
        calculate_critical_path_contribution,
        detect_retry_storm,
        detect_cascading_timeout,
        detect_connection_pool_issues,
        detect_all_sre_patterns,
    ],
)
